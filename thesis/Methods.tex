\section{Ogólne metody wykorzystane w~algorytmach głównych}\label{s_methods}

\subsection{Metoda podziału i ograniczeń}\label{ss_branch_and_bound}
\par{
  Metoda podziału i ograniczeń jest paradygmatem projektowania algorytmów
  rozwiązujących problemy optymalizacyjne z dziedziny kombinatoryki i obliczeń
  dyskretnych. 
  Algorytm zaprojektowany według tego paradygmatu polega na rozpatrywaniu
  poszczególnych \emph{rozwiązań kandydackich} poprzez przeszukiwanie
  przestrzeni stanów.
  Zbiór rozwiązań kandydackich tworzony jest w~postaci ukorzenionego drzewa,
  gdzie korzeń stanowi rozwiązanie określone pełnym, nieograniczonym zbiorem
  stanów.
  Algorytm odwiedza kolejne gałęzie drzewa (podział), reprezentujące poszczególne
  podzbiory zbioru rozwiązań.
  Zanim jednak dana gałąź~drzewa poszukiwań zostanie odwiedzona, dokonywane jest
  sprawdzenie szacunkowych dolnych i górnych granic wartości pewnej funkcji 
  ograniczającej $f$.
  w~przypadku, gdy wartości te odbiegają od znalezionego dotychczas przez
  algorytm lub zadanego optimum, cała gałąź jest odrzucana---nie istnieje w
  niej rozwiązanie spełniające założone wymagania. 
}
\par{
  Koncepcja algorymów działających zgodnie z metodą podziału i ograniczeń
  została wprowadzona w~\cite{land60} i~stanowi najpopularniejsze podejście
  w~rowiązywaniu problemów klasy $\mathcal{NP}$-trudnych.
}
\subsection{Programowanie liniowe}\label{ss_lp}
\par{
  Programowanie liniowe, zwane również optymalizacją liniową, stanowi sposób
  osiągania najlepszego możliwego wyniku (zazwyczaj maksimum lub minimum) w~modelu 
  matematycznym o wymaganiach określonych nierównościami liniowymi.
}
\par{
  Formalnie, mianem programowania liniowego określa się technikę optymalizacji 
  liniowej \emph{funkcji celu}, poddawanej \emph{ograniczeniom} w~postaci równań 
  lub nierówności liniowych.
  \emph{Region dopuszczalnych rozwiązań} stanowi wypukły wielokąt stanowiący 
  zbiór powstały w~wyniku przecięcia skończonej ilości półpłaszczyn wyznaczanych 
  przez nierówności liniowe.
  Funkcja celu to funkcja liniowa $z(x) \in \mathbb{R}$ zdefiniowana na regionie
  dopuszczalnych rozwiązań.
  Algorytm programowania liniowego odnajduje punkt na wielościanie,
  gdzie $z$ osiąga wartość optymalną w~kontekście formulacji zadania jeżeli taki
  punkt istnieje. 
  Przykładowy zapis kanonicznej formy wyrażania programów liniowych:\\
  Zmaksymalizować funkcję celu:
  \begin{align*}
    \sum_{j=1}^{n} c_j x_j
  \end{align*}
  Przy ograniczeniach: \begin{align*}
    \sum_{j=1}^{n}a_{ij}x_j \leq b_i; i =1, 2, \ldots, m\\
    x_j \geq 0, j=1, 2, \ldots, n
  \end{align*}
  Nieco wygodniejszą~formą zapisu programów liniowych jest tzw.
  \emph{postać~wektorowa}:\\
  Zmaksymalizować funkcję celu:
  \begin{align*}
    z(x)={c^T}x
  \end{align*}
  Przy ograniczeniach: \begin{align*}
    Ax \leq b\\
    x\geq 0
  \end{align*}\\
  Gdzie:
  \begin{itemize}
    \item $x$ stanowi wektor zmiennych do wyznaczenia,
    \item $b$ oraz $c$ to wektory znanych współczynników,
    \item $A$ to macierz znanych współczynników,
    \item ${(\cdot)}^\mathrm{T}$ oznacza macierz transponowaną,
    \item $Ax \leq b, x\geq 0$ to ograniczenia określające wypukły wielokąt,
      na którym optymalizowana jest funkcja celu $c^{T}x$.
  \end{itemize}
}
\par{
  w~celu otrzymania optymalnego rozwiązania problemu programowania liniowego
  stosuje się jeden z~\emph{algorytmów programowania liniowego}.
  Do grupy algorytmów programowania liniowego zalicza się m.in.\ algorytm
  simplex lub algorytm ``na krzyż'' (criss-cross).
}
\par{
  Programowanie liniowe znajduje zastosowanie w~wielu dziedzinach nauki i~przemysłu. 
  Przykładem może być biznes i~ekonomia, zarówno jak i szeroko pojęta inżynieria.
  Techniki programowania liniowego są użyteczne przy problemach związanych 
  z~planowaniem, trasowaniem, harmonogramowaniem, przydziałem zadań oraz
  projektowaniem.
  Wynika to z~faktu, iż wiele rzeczywistych problemów w~dziedzinie badań
  operacyjnych, mających na celu optymalizację procesów decyzyjnych w~praktyce,
  może zostać wyrażone w~postaci zadań programowania liniowego.
  Wiele algorytmów rozwiązujących większe problemy optymalizacyjne wykorzystuje
  programowanie liniowe do rozwiązywania podproblemów częściowych jako zadania 
  programowania liniowego.
}
\subsubsection{\textbf{Dualność (dwoistość) problemów programowania liniowego}}
\label{sss_lp_duality}
\par{
  Cechą każdego problemu wyrażonego jako zadanie programowania liniowego,
  nazywanego problemem \emph{pierwotnym}, jest dwoistość.
  Oznacza to, że problem pierwotny może zostać przekształcony w~odpowiadający mu
  problem \emph{wtórny}, zapewniający górną granicę optimum problemu
  pierwotnego. 
  Przykładowo, pierwotny problem:\par
  Zmaksymalizować $c^{T}x$ przy ograniczeniach $Ax\leq b, x \geq 0$;\\
  zastąpić można odpowiadającym mu \emph{symetrycznym} problemem wtórnym,\par
  Zminimalizować $b^{T}y$ przy ograniczeniach $A^{T}y \geq c, y \geq 0$.\\
}
\par{
  Twierdzenia dualności oparte są na dwóch fundamentalnych koncepcjach:
  \begin{enumerate}
    \item Problem wtórny symetrycznego problemu dualnego dwoistego programu
      liniowego stanowi pierwotny program liniowy.
    \item Każde prawdopodobne rozwiązanie programu liniowego stanowi
      ograniczenie optimum funkcji celu jego problemu dualnego.
  \end{enumerate}

  \begin{theorem}[Twierdzenie o słabej dualności]
    Wartość funkcji celu problemu dualnego dla dowolnego prawdopodobnego
    rozwiązania jest większa bądź równa wartości funkcji celu pierwotnego dla
    dowolnego prawdopodobnego rozwiązania.
  \end{theorem}
  \begin{theorem}[Twierdzenie o silnej dualności]
    Jeżeli problem pierwotny posiada rozwiązanie optymalne $x*$, to problem 
    wtórny również posiada rozwiązanie optymalne $y*; c^{T}x*=b^{T}y*$.
  \end{theorem}
}

\par{
  w~kontekście niniejszej pracy, dualność problemów problemów programowania
  liniowego jest szczególnie wartościowa ze względu na fakt, iż problemem
  wtórnym względem problemu pokrycia wierzchołkowego dowolnego grafu jest 
  problem maksymalnego skojarzenia grafu.
}

\subsubsection{\textbf{Programowanie całkowitoliczbowe i relaksacje}}
\label{sss_ilp_relaxations}
\par{
  Programem liniowym całkowitoliczbowym nazywa się każdy program liniowy 
  z~dodatkowym ograniczeniem: $\forall_{x_n \in x}: x_n \in
  \mathbb{Z}~\refstepcounter{equation}(\theequation)\label{ilp_bound}$.
  Ograniczenie to zwane jest \emph{warukiem całkowitoliczbowości}.
  Większość problemów NP-trudnych jest wyrażalna w~postaci programu liniowego
  całkowitoliczbowego.
  Prowadzi to do wniosku, iż sam problem programowania liniowego
  całkowitoliczbowego jest NP-trudny, co zaproponowano w~\cite{Kar72}.
}
\par{  
  Charakterystyczną poddziedziną programowów całkowitoliczbowych są
  \emph{binarne programy całkowitoliczbowe}, charakteryzującę się zamianą
  ograniczenia z~programu całkowitoliczbowego~\eqref{ilp_bound}, na następujące:
  $\forall_{x_n \in x}: x_n \in \{0, 1\}~\refstepcounter{equation}(\theequation)\label{bilp_bound}$.
  Jedyne problemy programowania całkowitoliczbowego rozpatrywane w~niniejszej
  pracy dotyczyć będą wyłącznie binarnych programów całkowitoliczbowych.
}
\par{
  w~celu przekształcenia problemu NP-trudnego, wyrażonego w~postaci binarnego 
  programu całkowitoliczbowego, do problemu rozwiązywalnego w~czasie 
  wielomianowym, wyrażonego w~postaci programu liniowego, należy dokonać 
  \emph{relaksacji}.
  Istotą relaksacji jest zastąpienie warunku całkowitoliczbowości binarnego
  programu całkowitoliczbowego~\eqref{bilp_bound} na mniej restrykcyjne
  ograniczenie $\forall_{x_n\in x}: 0\leq x_n\leq 1$.
}
\par {
  Istotną cechą relaksacji jest jej \emph{dokładność}, która może zostać
  stwierdzona gdy współrzędne każdego z wierzchołków regionu dopuszczalnych 
  rozwiązań są liczbami całkowitymi.
  Mając do czynienia z dokładną relaksacją, można na jej podstawie wprost 
  rozwiązać odpowiadający program całkowitoliczbowy w~czasie wielomianowym.
  w~tym celu wykonać należy następujące kroki:
  \begin{enumerate}
    \item otrzymać optimum $x*$ programu liniowego,
    \item odnaleźć wierzchołek $x^{\prime}, z(x^{\prime})=z(x*)$,
      \item zwrócić $x^{\prime}$ jako rozwiązanie programu całkowitoliczbowego.
    \end{enumerate}
}

\subsection{Redukcja dziedziny do jądra problemu}\label{subsection_kernelization}
\par{
  Redukcja dziedziny do jądra problemu jest techniką wykorzystywaną przy
  rozwiązywaniu problemów $\mathcal{NP}$-zupełnych za pomocą parametryzacji.
  Istotą redukcji dziedziny do jądra problemu przy problemach dotyczących grafów
  jest transformacja grafu $G=(V,E), |V|=n$, przy danym parametrze $k$, w~inny
  graf $G^{\prime}=(V^{\prime}, E^{\prime}), V^{\prime} \subseteq V, E^{\prime} \subseteq E$
  wraz z parametrem $k^{\prime} \leq k$.
  Celem tego procesu jest ograniczenie wartości $n^{\prime}$ przez jak najmniejszą
  funkcję $f(k^{\prime})$.
  Graf $G^{\prime}$ nazywany jest \emph{jądrem}.
  w~przypadku parametryzacji problemu pokrycia wierzchołkowego, w~grafie
  $G^{\prime}$ istnieje pokrywa wierzchołkowa $VC^{\prime}, |VC^{\prime}|\leq k^{\prime}$ 
  wtedy i tylko wtedy, gdy w~grafie $G$ istnieje pokrywa wierzchołkowa $VC,
  |VC| \leq k$.
}
\par{
  Redukowalność dziedziny do jądra problemu jest cechą wyróżniającą problemy 
  należące do klasy $\mathcal{FPT}$ spośród grupy wszystkich znanych problemów.
  Rozbicie na podbproblemy lub działanie na zmniejszonej dziedzinie pozwala na
  rozwiązywanie problemów klasy $\mathcal{FPT}$ w~czasie wielomianowym przy
  ustaleniu ograniczeń dotyczących wartości paramametru $k$, dyktującego z kolei
  postać podproblemów lub poddziedziny.
  Po uzyskaniu jądra, jeżeli odpowiedź negatywna nie została udzielona
  w~międzyczasie, proces rozwiązywania problemu pokrycia wierzchołkowego
  wykonuje Algorytm~\ref{alg_VC1}.\ do momentu otrzymania konkretnego
  rezultatu.
}
\par{
  Niniejsza praca koncentruje się na opisie, implementacji oraz porównaniu
  empirycznych wyników czasu działania następujących metod redukcji dziedziny do
  jądra problemu:
  \begin{enumerate}
    \item redukcja przez usunięcie wierzchołków wysokiego stopnia, zaproponowana
      w~\cite{KernelizationAlgorithms04},
    \item algorytm zaproponowany w~\cite{KernelizationAlgorithms04}, polegający
      na redukcji opartej o programowanie liniowe: formulacji programu
      całkowitoliczbowego i rozwiązanie jego liniowej relaksacji,
    \item redukcja poprzez usunięcie koron grafu, zaproponowana
      w~\cite{abukhzam03},
    \item redukcja poprzez przebudowę oraz zwijanie koron grafu, zaproponowana
      w~\cite{ImprovedBounds10}.
  \end{enumerate}
}
