\section{Ogólne metody wykorzystane w~algorytmach głównych}\label{s_methods}

\subsection{Metoda podziału i ograniczeń}\label{ss_branch_and_bound}
\par{
  Metoda podziału i ograniczeń jest paradygmatem projektowania algorytmów rozwiązujących problemy optymalizacyjne z dziedziny kombinatoryki i optymalizacji dyskretnej.
  Algorytm zaprojektowany według tego paradygmatu polega na rozpatrywaniu poszczególnych \emph{rozwiązań-kandydatów} przez przeszukiwanie pewnej \emph{przestrzeni stanów}, zdefiniowanej dziedziną danych wejściowych.
  Zbiór tych rozwiązań tworzony jest w~postaci ukorzenionego drzewa, gdzie korzeń stanowi rozwiązanie określone pełnym, nieograniczonym zbiorem stanów czyli na przykład całością przestrzeni poszukiwań lub zbiorem pustym, w zależności od natury rozwiązywanego problemu.
  Algorytm odwiedza kolejne gałęzie drzewa (podział), reprezentujące poszczególne
  podzbiory pełnego zbioru rozwiązań.
  Zanim jednak dana gałąź~drzewa poszukiwań zostanie odwiedzona, dokonywane jest sprawdzenie szacunkowych dolnych i górnych granic wartości pewnej funkcji ograniczającej $f$.
  W~przypadku, gdy wartości te są gorsze od znalezionego dotychczas przez algorytm lub zadanego jako parametr wejściowy optimum wartości funkcji $f$, cała gałąź jest odrzucana --- nie istnieje w niej rozwiązanie spełniające założone wymagania.
}
\par{
  Koncepcja algorytmów działających zgodnie z metodą podziału i ograniczeń została wprowadzona w~pracy~\cite{land60} i~stanowi najpopularniejsze podejście w~rowiązywaniu problemów $\mathcal{NP}$-trudnych.
}
\subsection{Programowanie liniowe}\label{ss_lp}
\par{
  Programowanie liniowe, zwane również optymalizacją liniową, stanowi sposób
  osiągania najlepszego możliwego wyniku (zazwyczaj maksimum lub minimum) w~modelu 
  matematycznym o wymaganiach określonych nierównościami liniowymi.
}
\par{
  Formalnie mianem programowania liniowego określa się technikę optymalizacji liniowej \emph{funkcji celu}, poddawanej \emph{ograniczeniom} w~postaci równań lub nierówności liniowych.
  \emph{Region dopuszczalnych rozwiązań} to wypukły wielościan stanowiący zbiór powstały w~wyniku przecięcia skończonej liczby półpłaszczyn wyznaczanych przez nierówności liniowe.
  Funkcja celu to funkcja liniowa $z(x) \in \mathbb{R}$ zdefiniowana na regionie dopuszczalnych rozwiązań.
  Algorytm programowania liniowego odnajduje na wielościanie punkt, w którym funkcja $z$ osiąga wartość optymalną w~kontekście sformułowania zadania, jeżeli taki punkt istnieje --- w przeciwnym wypadku dane sformułowanie problemu programowania liniowego jest \emph{nieograniczone}.
  Przykładowy zapis programu liniowego wygląda następująco:\\
  Zmaksymalizować funkcję celu:
  \begin{align*}
    \sum_{j=1}^{n} c_j x_j
  \end{align*}
  Przy ograniczeniach: \begin{align*}
    \sum_{j=1}^{n}a_{ij}x_j \leq b_i; i =1, 2, \ldots, m\\
    x_j \geq 0, j=1, 2, \ldots, n
  \end{align*}
  Nieco wygodniejszą~formą zapisu programów liniowych jest tak zwana \emph{postać~wektorowa}, zapisywana w następujący sposób.\\
  Zmaksymalizować funkcję celu:
  \begin{align*}
    z(x)={c^T}x
  \end{align*}
  Przy ograniczeniach: \begin{align*}
    Ax \leq b\\
    x\geq 0
  \end{align*}\\
  gdzie:
  \begin{itemize}
    \item $x$ stanowi wektor zmiennych do wyznaczenia,
    \item $b$ oraz $c$ to wektory znanych współczynników,
    \item $A$ to macierz znanych współczynników,
    \item ${(\cdot)}^\mathrm{T}$ oznacza macierz transponowaną,
    \item $Ax \leq b, x\geq 0$ to ograniczenia określające wypukły wielokąt,
      na którym optymalizowana jest funkcja celu $c^{T}x$.
  \end{itemize}
}
\par{
  w~celu otrzymania optymalnego rozwiązania problemu programowania liniowego
  stosuje się jeden z~\emph{algorytmów programowania liniowego}.
  Do grupy algorytmów programowania liniowego zalicza się m.in.\ algorytm
  simpleks lub algorytm ``na krzyż'' (ang. \emph{criss-cross}).
}
\par{
  Programowanie liniowe znajduje zastosowanie w~wielu dziedzinach nauki i~przemysłu. 
  Przykładem może być biznes i~ekonomia, zarówno jak i szeroko pojęta inżynieria.
  Techniki programowania liniowego są użyteczne przy problemach związanych 
  z~planowaniem, trasowaniem, harmonogramowaniem, przydziałem zadań oraz
  projektowaniem.
  Wynika to z~faktu, iż wiele rzeczywistych problemów w~dziedzinie badań
  operacyjnych mających na celu optymalizację procesów decyzyjnych w~praktyce,
  może zostać wyrażone w~postaci zadań programowania liniowego.
  Wiele algorytmów rozwiązujących większe problemy optymalizacyjne wykorzystuje
  programowanie liniowe do rozwiązywania podproblemów częściowych jako zadania 
  programowania liniowego.
}
\subsubsection{\textbf{Dualność (dwoistość) problemów programowania liniowego}}
\label{sss_lp_duality}
\par{
  Cechą każdego problemu wyrażonego jako zadanie programowania liniowego,
  nazywanego problemem \emph{pierwotnym}, jest dwoistość.
  Oznacza to, że problem pierwotny może zostać przekształcony w~odpowiadający mu
  problem \emph{dualny}, zapewniający górną granicę optimum problemu
  pierwotnego. 
  Przykładowo, pierwotny problem o postaci:\[
  \textnormal{Zmaksymalizować $c^{T}x$ przy ograniczeniach $Ax\leq b, x \geq 0$}
  \]
  zastąpić można odpowiadającym mu \emph{symetrycznym} problemem wtórnym.
  \[
  \textnormal{Zminimalizować $b^{T}y$ przy ograniczeniach $A^{T}y \geq c, y \geq 0$.}
  \]
}
\par{
  Twierdzenia dualności oparte są na dwóch fundamentalnych koncepcjach.
  \begin{enumerate}
    \item Problem wtórny symetrycznego problemu dualnego dwoistego programu
      liniowego stanowi pierwotny program liniowy.
    \item Każde prawdopodobne rozwiązanie programu liniowego stanowi
      ograniczenie optimum funkcji celu jego problemu dualnego.
  \end{enumerate}

  \begin{theorem}[Twierdzenie o słabej dualności~\cite{Boyd:2004:CO:993483}]
    Wartość funkcji celu problemu dualnego dla dowolnego prawdopodobnego
    rozwiązania jest większa bądź równa wartości funkcji celu pierwotnego dla
    dowolnego prawdopodobnego rozwiązania.
  \end{theorem}
  \begin{theorem}[Twierdzenie o silnej dualności~\cite{Boyd:2004:CO:993483}]
    Jeżeli problem pierwotny ma rozwiązanie optymalne $x^*$, to problem 
    wtórny również ma rozwiązanie optymalne $y^*$ takie, że $c^{T}x^*=b^{T}y^*$.
  \end{theorem}
}

\par{
  w~kontekście niniejszej pracy dualność problemów problemów programowania
  liniowego jest szczególnie wartościowa ze względu na to, że problemem
  wtórnym względem problemu pokrycia wierzchołkowego dowolnego grafu jest 
  problem maksymalnego skojarzenia grafu.
}

\subsubsection{\textbf{Programowanie całkowitoliczbowe i relaksacje}}
\label{sss_ilp_relaxations}
\par{
  Całkowitoliczbowym programem liniowym nazywa się każdy program liniowy 
  z~dodatkowym ograniczeniem: $\forall_{x_n \in x}: x_n \in
  \mathbb{Z}$\label{ilp_bound}.
  Ograniczenie to stanowi \emph{warunek całkowitoliczbowości}.
  Większość problemów $\mathcal{NP}$-trudnych jest wyrażalna w~postaci całkowitoliczbowego programu liniowego.
  Prowadzi to do wniosku, że sam problem całkowitoliczbowego programowania liniowego jest $\mathcal{NP}$-trudny, co zaproponowano w pracy~\cite{Kar72}.
}
\par{  
  Charakterystyczną poddziedziną programów całkowitoliczbowych są
  \emph{binarne programy całkowitoliczbowe}, charakteryzującę się zamianą
  ograniczenia z~programu całkowitoliczbowego na następujące:
  $\forall_{x_n \in x}: x_n \in \{0, 1\}\label{bilp_bound}$.
  Jedyne problemy programowania całkowitoliczbowego rozpatrywane w~niniejszej
  pracy dotyczyć będą wyłącznie binarnych programów całkowitoliczbowych.
}
\par{
  w~celu przekształcenia problemu $\mathcal{NP}$-trudnego, wyrażonego w~postaci binarnego programu całkowitoliczbowego do problemu rozwiązywalnego w~czasie wielomianowym, wyrażonego w~postaci programu liniowego należy wykonać operację \emph{relaksacji}.
  Istotą relaksacji jest zastąpienie warunku całkowitoliczbowości binarnego
  programu całkowitoliczbowego~\eqref{bilp_bound} na mniej restrykcyjne
  ograniczenie $\forall_{x_n\in x}: 0\leq x_n\leq 1$.
}
\par {
  Istotną cechą relaksacji jest jej \emph{dokładność}, która może zostać
  stwierdzona, gdy współrzędne każdego z wierzchołków regionu dopuszczalnych 
  rozwiązań są liczbami całkowitymi.
  Mając do czynienia z dokładną relaksacją, można na jej podstawie wprost 
  rozwiązać odpowiadający program całkowitoliczbowy w~czasie wielomianowym.
  w~tym celu wykonać należy następujące kroki.
  \begin{enumerate}
    \item Obliczyć optimum $x^*$ programu liniowego.
    \item Odnaleźć wierzchołek $x^{\prime}$ taki, że $z(x^{\prime})=z(x^*)$.
    \item Zwrócić $x^{\prime}$ jako rozwiązanie programu całkowitoliczbowego.
  \end{enumerate}
}

\subsection{Redukcja dziedziny do jądra problemu}\label{subsection_kernelization}
\par{
  Redukcja dziedziny do jądra problemu jest techniką wykorzystywaną przy
  rozwiązywaniu problemów $\mathcal{NP}$-zupełnych za pomocą parametryzacji.
  Istotą redukcji dziedziny do jądra problemu przy problemach dotyczących grafów
  jest transformacja grafu $G=(V,E)$ o rozmiarze $|V|=n$ przy danym parametrze $k$ w~inny
  graf $G^{\prime}=(V^{\prime}, E^{\prime})$ taki, że $V^{\prime} \subseteq V, E^{\prime} \subseteq E$
  wraz z parametrem $k^{\prime} \leq k$.
  Celem tego procesu jest ograniczenie wartości $n^{\prime}$ przez jak najmniejszą
  funkcję $f(k^{\prime})$.
  Graf $G^{\prime}$ nazywany jest \emph{jądrem} dziedziny problemu.
  w~przypadku parametryzacji problemu pokrycia wierzchołkowego, w~grafie
  $G^{\prime}$ pokrycie wierzchołkowe $C^{\prime}$, o rozmiarze $|C^{\prime}|\leq k^{\prime}$ istnieje wtedy i tylko wtedy, gdy w~grafie $G$ istnieje pokrycie wierzchołkowe $C$ o liczebności $|C| \leq k$.
}
\par{
  Redukowalność dziedziny do jądra problemu jest cechą wyróżniającą problemy 
  należące do klasy $\mathcal{FPT}$ spośród grupy wszystkich znanych problemów.
  Rozbicie na podbproblemy lub działanie na zmniejszonej dziedzinie pozwala na
  rozwiązywanie problemów klasy $\mathcal{FPT}$ w~czasie wielomianowym przy
  ustaleniu ograniczeń dotyczących wartości paramametru $k$, dyktującego z kolei
  postać podproblemów lub poddziedziny.
  Po uzyskaniu jądra, jeżeli w~międzyczasie nie została udzielona odpowiedź negatywna, proces rozwiązywania problemu pokrycia wierzchołkowego
  wykonuje algorytm~\ref{alg_VC1}\ do momentu otrzymania jednozancznego rezultatu.
}
\par{
  Niniejsza praca koncentruje się na opisie, implementacji oraz porównaniu
  empirycznych wyników czasu działania następujących metod redukcji dziedziny do
  jądra problemu:
  \begin{enumerate}
    \item Redukcja przez usunięcie wierzchołków wysokiego stopnia, zaproponowana
      w~pracy~\cite{KernelizationAlgorithms04}.
    \item Algorytm zaproponowany w~\cite{KernelizationAlgorithms04}, polegający
      na redukcji opartej na programowaniu liniowym: formulacji programu
      całkowitoliczbowego i rozwiązanie jego liniowej relaksacji.
    \item Redukcja przez usunięcie koron grafu, zaproponowana
      w~pracy~\cite{abukhzam03}.
    \item Redukcja przez przebudowę oraz zwijanie koron grafu, zaproponowana
      w~pracy~\cite{ImprovedBounds10}.
  \end{enumerate}
}
